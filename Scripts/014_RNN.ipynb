{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8505a37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 7.4 kB/s              ��█████████████▌             | 510.4 MB 110.4 MB/s eta 0:00:04\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch) (4.0.1)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.10.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411cd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.6.2-cp36-cp36m-manylinux2010_x86_64.whl (458.3 MB)\n",
      "     |████████████████████████████████| 458.3 MB 9.2 kB/s              MB/s eta 0:00:01��███████▏ | 432.3 MB 92.9 MB/s eta 0:00:01 0:00:01 \n",
      "\u001b[?25hCollecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.19.5)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras<2.7,>=2.6.0\n",
      "  Downloading keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 79.7 MB/s            \n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.37.0\n",
      "  Downloading grpcio-1.47.0-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
      "     |████████████████████████████████| 4.5 MB 23.6 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: h5py~=3.1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: wheel~=0.35 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: six~=1.15.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (1.15.0)\n",
      "Collecting tensorboard<2.7,>=2.6.0\n",
      "  Downloading tensorboard-2.6.0-py3-none-any.whl (5.6 MB)\n",
      "     |████████████████████████████████| 5.6 MB 56.6 MB/s            \n",
      "\u001b[?25hCollecting clang~=5.0\n",
      "  Downloading clang-5.0.tar.gz (30 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     |████████████████████████████████| 42 kB 2.2 MB/s             \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (3.15.2)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     |████████████████████████████████| 65 kB 7.0 MB/s             \n",
      "\u001b[?25hCollecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "     |████████████████████████████████| 132 kB 97.0 MB/s            \n",
      "\u001b[?25hCollecting tensorflow-estimator<2.7,>=2.6.0\n",
      "  Downloading tensorflow_estimator-2.6.0-py2.py3-none-any.whl (462 kB)\n",
      "     |████████████████████████████████| 462 kB 100.8 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: google-pasta~=0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorflow) (0.2.0)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: cached-property in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from h5py~=3.1.0->tensorflow) (1.5.1)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.35.0-py2.py3-none-any.whl (152 kB)\n",
      "     |████████████████████████████████| 152 kB 65.4 MB/s            \n",
      "\u001b[?25hCollecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "     |████████████████████████████████| 97 kB 12.6 MB/s            \n",
      "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "     |████████████████████████████████| 4.9 MB 77.7 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: setuptools>=41.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (49.6.0.post20210108)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.0.2)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     |████████████████████████████████| 781 kB 49.0 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tensorboard<2.7,>=2.6.0->tensorflow) (2.26.0)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (4.7.2)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "     |████████████████████████████████| 155 kB 47.7 MB/s            \n",
      "\u001b[?25hCollecting cachetools<5.0,>=2.0.0\n",
      "  Downloading cachetools-4.2.4-py3-none-any.whl (10 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Collecting importlib-metadata>=4.4\n",
      "  Downloading importlib_metadata-4.8.3-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2021.5.30)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (1.26.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests<3,>=2.21.0->tensorboard<2.7,>=2.6.0->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from werkzeug>=0.11.15->tensorboard<2.7,>=2.6.0->tensorflow) (0.8)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.7,>=2.6.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.7,>=2.6.0->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     |████████████████████████████████| 151 kB 75.6 MB/s            \n",
      "\u001b[?25hBuilding wheels for collected packages: clang, termcolor\n",
      "  Building wheel for clang (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for clang: filename=clang-5.0-py3-none-any.whl size=30702 sha256=154f12df975214051b2c80eab8edd4700cb1b33d7e556d925914548accf4c391\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/22/4c/94/0583f60c9c5b6024ed64f290cb2d43b06bb4f75577dc3c93a7\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4829 sha256=f106f64cbd8bddffdde6a5851c492d1dfc9e747a09b8d01d832845d5c8a13734\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/93/2a/eb/e58dbcbc963549ee4f065ff80a59f274cc7210b6eab962acdc\n",
      "Successfully built clang termcolor\n",
      "Installing collected packages: typing-extensions, pyasn1-modules, oauthlib, cachetools, requests-oauthlib, importlib-metadata, google-auth, tensorboard-plugin-wit, tensorboard-data-server, markdown, grpcio, google-auth-oauthlib, absl-py, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-preprocessing, keras, gast, flatbuffers, clang, astunparse, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 4.0.1\n",
      "    Uninstalling typing-extensions-4.0.1:\n",
      "      Successfully uninstalled typing-extensions-4.0.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.7.0\n",
      "    Uninstalling importlib-metadata-3.7.0:\n",
      "      Successfully uninstalled importlib-metadata-3.7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pylint 2.12.2 requires typing-extensions>=3.10.0; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "astroid 2.9.0 requires typing-extensions>=3.10; python_version < \"3.10\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
      "aiobotocore 1.3.0 requires botocore<1.20.50,>=1.20.49, but you have botocore 1.24.42 which is incompatible.\u001b[0m\n",
      "Successfully installed absl-py-0.15.0 astunparse-1.6.3 cachetools-4.2.4 clang-5.0 flatbuffers-1.12 gast-0.4.0 google-auth-1.35.0 google-auth-oauthlib-0.4.6 grpcio-1.47.0 importlib-metadata-4.8.3 keras-2.6.0 keras-preprocessing-1.1.2 markdown-3.3.7 oauthlib-3.2.0 opt-einsum-3.3.0 pyasn1-modules-0.2.8 requests-oauthlib-1.3.1 tensorboard-2.6.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.6.2 tensorflow-estimator-2.6.0 termcolor-1.1.0 typing-extensions-3.7.4.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e28669c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "tf.config.run_functions_eagerly(True)\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import datetime\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac3e3a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/Full_train_test_split/df_full_end_test.csv')\n",
    "df = df.drop(columns = [\"Unnamed: 0\", \"1_hr_std\",\"2_hr_std\",\"3_hr_std\", \"4_hr_std\", \"standardised_texts\",\"2_hr\",\"1_hr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "291469e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>temp_weighted</th>\n",
       "      <th>cloud_cover_weighted</th>\n",
       "      <th>rainfall_weighted</th>\n",
       "      <th>abnormal</th>\n",
       "      <th>polarity</th>\n",
       "      <th>3_hr</th>\n",
       "      <th>4_hr</th>\n",
       "      <th>daily_policy_index</th>\n",
       "      <th>train_test</th>\n",
       "      <th>hour</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chunk</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-10-25 19:00:00</th>\n",
       "      <td>57</td>\n",
       "      <td>10.409742</td>\n",
       "      <td>73.715648</td>\n",
       "      <td>0.016261</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>16</td>\n",
       "      <td>14</td>\n",
       "      <td>196.24</td>\n",
       "      <td>train</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25 20:00:00</th>\n",
       "      <td>102</td>\n",
       "      <td>10.386005</td>\n",
       "      <td>75.509971</td>\n",
       "      <td>0.014549</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>44</td>\n",
       "      <td>16</td>\n",
       "      <td>196.24</td>\n",
       "      <td>train</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25 21:00:00</th>\n",
       "      <td>99</td>\n",
       "      <td>10.134989</td>\n",
       "      <td>81.518421</td>\n",
       "      <td>0.017371</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>37</td>\n",
       "      <td>44</td>\n",
       "      <td>196.24</td>\n",
       "      <td>train</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25 22:00:00</th>\n",
       "      <td>88</td>\n",
       "      <td>9.803373</td>\n",
       "      <td>80.854104</td>\n",
       "      <td>0.006652</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>57</td>\n",
       "      <td>37</td>\n",
       "      <td>196.24</td>\n",
       "      <td>train</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-25 23:00:00</th>\n",
       "      <td>73</td>\n",
       "      <td>9.872040</td>\n",
       "      <td>83.125380</td>\n",
       "      <td>0.002621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064641</td>\n",
       "      <td>102</td>\n",
       "      <td>57</td>\n",
       "      <td>196.24</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     texts  temp_weighted  cloud_cover_weighted  \\\n",
       "chunk                                                             \n",
       "2018-10-25 19:00:00     57      10.409742             73.715648   \n",
       "2018-10-25 20:00:00    102      10.386005             75.509971   \n",
       "2018-10-25 21:00:00     99      10.134989             81.518421   \n",
       "2018-10-25 22:00:00     88       9.803373             80.854104   \n",
       "2018-10-25 23:00:00     73       9.872040             83.125380   \n",
       "\n",
       "                     rainfall_weighted  abnormal  polarity  3_hr  4_hr  \\\n",
       "chunk                                                                    \n",
       "2018-10-25 19:00:00           0.016261         0  0.064641    16    14   \n",
       "2018-10-25 20:00:00           0.014549         0  0.064641    44    16   \n",
       "2018-10-25 21:00:00           0.017371         0  0.064641    37    44   \n",
       "2018-10-25 22:00:00           0.006652         0  0.064641    57    37   \n",
       "2018-10-25 23:00:00           0.002621         0  0.064641   102    57   \n",
       "\n",
       "                     daily_policy_index train_test  hour weekday  \n",
       "chunk                                                             \n",
       "2018-10-25 19:00:00              196.24      train    19       3  \n",
       "2018-10-25 20:00:00              196.24      train    20       3  \n",
       "2018-10-25 21:00:00              196.24      train    21       3  \n",
       "2018-10-25 22:00:00              196.24      train    22       3  \n",
       "2018-10-25 23:00:00              196.24      train    23       3  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['chunk'] = pd.to_datetime(df['chunk'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "df['hour'] = df['chunk'].dt.hour\n",
    "df['weekday'] = df['chunk'].dt.dayofweek\n",
    "df['weekday'] = df['weekday'].astype(\"category\")\n",
    "df = df.set_index('chunk')\n",
    "df[\"abnormal\"] = df[\"abnormal\"].astype('int')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8625c79e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31682"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e23503b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "ss = StandardScaler()\n",
    "ss_y = StandardScaler()\n",
    "\n",
    "train = df.loc[df['train_test'] == \"train\"]\n",
    "train = train.drop(columns = [\"train_test\"])\n",
    "train = train.astype('float')\n",
    "test = df.loc[df['train_test'] == \"test\"]\n",
    "train = train.astype('float')\n",
    "test = test.drop(columns = [\"train_test\"])\n",
    "\n",
    "y_train = train.iloc[:, 0:1] \n",
    "X_train = train\n",
    "X_train = X_train.drop(columns = [\"abnormal\", \"texts\"])\n",
    "\n",
    "y_test = test.iloc[:, 0:1] \n",
    "X_test = test\n",
    "X_test = X_test.drop(columns = [\"abnormal\", \"texts\"])\n",
    "\n",
    "X_train = ss.fit_transform(X_train)\n",
    "y_train = ss_y.fit_transform(y_train)\n",
    "#y_train = y_train.to_numpy()\n",
    "X_test = ss.transform(X_test)\n",
    "y_test = ss_y.transform(y_test)\n",
    "#y_test = y_test.to_numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "87bdbf31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-5.51881121e-02,  1.11781152e+00, -4.51298350e-01, ...,\n",
       "        -4.62302402e-01,  1.08323079e+00, -4.12114438e-04],\n",
       "       [-5.95733121e-02,  1.19849523e+00, -4.57447450e-01, ...,\n",
       "        -4.62302402e-01,  1.22768641e+00, -4.12114438e-04],\n",
       "       [-1.05945991e-01,  1.46867179e+00, -4.47308587e-01, ...,\n",
       "        -4.62302402e-01,  1.37214202e+00, -4.12114438e-04],\n",
       "       ...,\n",
       "       [ 3.23043577e-01,  1.27894930e+00, -3.53644407e-01, ...,\n",
       "         4.05988891e-01,  1.22768641e+00,  4.99787306e-01],\n",
       "       [ 2.69069105e-01,  1.42600662e+00, -4.15595759e-01, ...,\n",
       "         4.05988891e-01,  1.37214202e+00,  4.99787306e-01],\n",
       "       [ 2.78718906e-01,  1.08357424e+00, -5.09714792e-01, ...,\n",
       "         4.05988891e-01,  1.51659763e+00,  4.99787306e-01]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45321ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_train[24000: , :]\n",
    "y_val = y_train[24000: , :]\n",
    "X_train = X_train[:-3916 , :]\n",
    "y_train = y_train[:-3916 , :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a7b3108c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape (24000, 9) (24000, 1)\n",
      "Testing Shape (3766, 9) (3766, 1)\n",
      "Validation Shape (3916, 9) (3916, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Shape\", X_train.shape, y_train.shape)\n",
    "print(\"Testing Shape\", X_test.shape, y_test.shape) \n",
    "print(\"Validation Shape\", X_val.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "41d0c35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    # Shape [batch, time, features] => [batch, lstm_units]\n",
    "    # Adding more `lstm_units` just overfits more quickly.\n",
    "    tf.keras.layers.LSTM(34, input_shape=(1,9),return_sequences=False),\n",
    "    # Shape => [batch, out_steps*features]\n",
    "    tf.keras.layers.Dense(24*9,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    tf.keras.layers.Dense(1,\n",
    "                          kernel_initializer=tf.initializers.zeros()),\n",
    "    # Shape => [batch, out_steps, features]\n",
    "    #tf.keras.layers.Reshape([1, 1])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "928ee0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[tf.metrics.MeanAbsoluteError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "626d9b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 34)                5984      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 216)               7560      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 217       \n",
      "=================================================================\n",
      "Total params: 13,761\n",
      "Trainable params: 13,761\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "7fb8c47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight = {0: 0.5, 1: 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6cb982f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "  4/334 [..............................] - ETA: 8s - loss: 0.9876 - mean_absolute_error: 0.7657 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py:4212: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 7s 19ms/step - loss: 0.9022 - mean_absolute_error: 0.7242 - val_loss: 1.6715 - val_mean_absolute_error: 0.9435\n",
      "Epoch 2/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.9005 - mean_absolute_error: 0.7171 - val_loss: 1.6735 - val_mean_absolute_error: 0.9441\n",
      "Epoch 3/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.9005 - mean_absolute_error: 0.7164 - val_loss: 1.6682 - val_mean_absolute_error: 0.9426\n",
      "Epoch 4/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7165 - val_loss: 1.6728 - val_mean_absolute_error: 0.9439\n",
      "Epoch 5/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7174 - val_loss: 1.6773 - val_mean_absolute_error: 0.9451\n",
      "Epoch 6/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.9005 - mean_absolute_error: 0.7169 - val_loss: 1.6811 - val_mean_absolute_error: 0.9462\n",
      "Epoch 7/100\n",
      "334/334 [==============================] - 8s 23ms/step - loss: 0.9005 - mean_absolute_error: 0.7159 - val_loss: 1.6657 - val_mean_absolute_error: 0.9419\n",
      "Epoch 8/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7172 - val_loss: 1.6795 - val_mean_absolute_error: 0.9458\n",
      "Epoch 9/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.9006 - mean_absolute_error: 0.7167 - val_loss: 1.6777 - val_mean_absolute_error: 0.9453\n",
      "Epoch 10/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7170 - val_loss: 1.6852 - val_mean_absolute_error: 0.9473\n",
      "Epoch 11/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9006 - mean_absolute_error: 0.7161 - val_loss: 1.6748 - val_mean_absolute_error: 0.9445\n",
      "Epoch 12/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.9005 - mean_absolute_error: 0.7168 - val_loss: 1.6759 - val_mean_absolute_error: 0.9448\n",
      "Epoch 13/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7172 - val_loss: 1.6844 - val_mean_absolute_error: 0.9471\n",
      "Epoch 14/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7161 - val_loss: 1.6743 - val_mean_absolute_error: 0.9443\n",
      "Epoch 15/100\n",
      "334/334 [==============================] - 8s 22ms/step - loss: 0.9005 - mean_absolute_error: 0.7163 - val_loss: 1.6696 - val_mean_absolute_error: 0.9430\n",
      "Epoch 16/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.9005 - mean_absolute_error: 0.7171 - val_loss: 1.6818 - val_mean_absolute_error: 0.9464\n",
      "Epoch 17/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.9005 - mean_absolute_error: 0.7167 - val_loss: 1.6772 - val_mean_absolute_error: 0.9451\n",
      "Epoch 18/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9006 - mean_absolute_error: 0.7168 - val_loss: 1.6810 - val_mean_absolute_error: 0.9462\n",
      "Epoch 19/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7162 - val_loss: 1.6764 - val_mean_absolute_error: 0.9449\n",
      "Epoch 20/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7168 - val_loss: 1.6792 - val_mean_absolute_error: 0.9457\n",
      "Epoch 21/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9006 - mean_absolute_error: 0.7171 - val_loss: 1.6908 - val_mean_absolute_error: 0.9488\n",
      "Epoch 22/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7162 - val_loss: 1.6863 - val_mean_absolute_error: 0.9476\n",
      "Epoch 23/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7161 - val_loss: 1.6692 - val_mean_absolute_error: 0.9429\n",
      "Epoch 24/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7172 - val_loss: 1.6778 - val_mean_absolute_error: 0.9453\n",
      "Epoch 25/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9006 - mean_absolute_error: 0.7170 - val_loss: 1.6849 - val_mean_absolute_error: 0.9472\n",
      "Epoch 26/100\n",
      "334/334 [==============================] - 7s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7164 - val_loss: 1.6754 - val_mean_absolute_error: 0.9446\n",
      "Epoch 27/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7174 - val_loss: 1.6858 - val_mean_absolute_error: 0.9475\n",
      "Epoch 28/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7157 - val_loss: 1.6733 - val_mean_absolute_error: 0.9440\n",
      "Epoch 29/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7168 - val_loss: 1.6706 - val_mean_absolute_error: 0.9433\n",
      "Epoch 30/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7163 - val_loss: 1.6668 - val_mean_absolute_error: 0.9423\n",
      "Epoch 31/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9006 - mean_absolute_error: 0.7168 - val_loss: 1.6749 - val_mean_absolute_error: 0.9445\n",
      "Epoch 32/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7166 - val_loss: 1.6758 - val_mean_absolute_error: 0.9447\n",
      "Epoch 33/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7172 - val_loss: 1.6829 - val_mean_absolute_error: 0.9467\n",
      "Epoch 34/100\n",
      "334/334 [==============================] - 7s 21ms/step - loss: 0.9005 - mean_absolute_error: 0.7162 - val_loss: 1.6795 - val_mean_absolute_error: 0.9458\n",
      "Epoch 35/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7170 - val_loss: 1.6784 - val_mean_absolute_error: 0.9454\n",
      "Epoch 36/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7168 - val_loss: 1.6861 - val_mean_absolute_error: 0.9475\n",
      "Epoch 37/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.9005 - mean_absolute_error: 0.7166 - val_loss: 1.6775 - val_mean_absolute_error: 0.9452\n",
      "Epoch 38/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7166 - val_loss: 1.6827 - val_mean_absolute_error: 0.9466\n",
      "Epoch 39/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7166 - val_loss: 1.6759 - val_mean_absolute_error: 0.9448\n",
      "Epoch 40/100\n",
      "334/334 [==============================] - 7s 22ms/step - loss: 0.9005 - mean_absolute_error: 0.7173 - val_loss: 1.6888 - val_mean_absolute_error: 0.9483\n",
      "Epoch 41/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7167 - val_loss: 1.6852 - val_mean_absolute_error: 0.9473\n",
      "Epoch 42/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7164 - val_loss: 1.6816 - val_mean_absolute_error: 0.9463\n",
      "Epoch 43/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7159 - val_loss: 1.6685 - val_mean_absolute_error: 0.9427\n",
      "Epoch 44/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9006 - mean_absolute_error: 0.7170 - val_loss: 1.6767 - val_mean_absolute_error: 0.9450\n",
      "Epoch 45/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7168 - val_loss: 1.6795 - val_mean_absolute_error: 0.9457\n",
      "Epoch 46/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7163 - val_loss: 1.6744 - val_mean_absolute_error: 0.9444\n",
      "Epoch 47/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7171 - val_loss: 1.6780 - val_mean_absolute_error: 0.9453\n",
      "Epoch 48/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7171 - val_loss: 1.6877 - val_mean_absolute_error: 0.9480\n",
      "Epoch 49/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7165 - val_loss: 1.6860 - val_mean_absolute_error: 0.9475\n",
      "Epoch 50/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7164 - val_loss: 1.6724 - val_mean_absolute_error: 0.9438\n",
      "Epoch 51/100\n",
      "334/334 [==============================] - 6s 17ms/step - loss: 0.9005 - mean_absolute_error: 0.7169 - val_loss: 1.6807 - val_mean_absolute_error: 0.9461\n",
      "Epoch 52/100\n",
      "334/334 [==============================] - 7s 20ms/step - loss: 0.9005 - mean_absolute_error: 0.7161 - val_loss: 1.6742 - val_mean_absolute_error: 0.9443\n",
      "Epoch 53/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7165 - val_loss: 1.6763 - val_mean_absolute_error: 0.9449\n",
      "Epoch 54/100\n",
      "334/334 [==============================] - 6s 19ms/step - loss: 0.9005 - mean_absolute_error: 0.7172 - val_loss: 1.6778 - val_mean_absolute_error: 0.9453\n",
      "Epoch 55/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7169 - val_loss: 1.6820 - val_mean_absolute_error: 0.9464\n",
      "Epoch 56/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9006 - mean_absolute_error: 0.7161 - val_loss: 1.6763 - val_mean_absolute_error: 0.9449\n",
      "Epoch 57/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7164 - val_loss: 1.6744 - val_mean_absolute_error: 0.9443\n",
      "Epoch 58/100\n",
      "334/334 [==============================] - 6s 18ms/step - loss: 0.9005 - mean_absolute_error: 0.7165 - val_loss: 1.6701 - val_mean_absolute_error: 0.9432\n",
      "Epoch 59/100\n",
      "326/334 [============================>.] - ETA: 0s - loss: 0.8934 - mean_absolute_error: 0.7153"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-185792f62cbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m model.fit(X_train.reshape(-1,1,9), y_train,\n\u001b[0;32m----> 2\u001b[0;31m           validation_data=(X_val.reshape(-1,1,9), y_val), epochs = 100, batch_size=72)\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    851\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    852\u001b[0m         \u001b[0;34m\"\"\"Runs a training execution with one step.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 853\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mstep_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 842\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    843\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    844\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1284\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1285\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1286\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2847\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2848\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2849\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2851\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3630\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3631\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3632\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3634\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    595\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 835\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    836\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    789\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[1;32m    790\u001b[0m     \u001b[0;31m# Run backwards pass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m     \u001b[0;31m# Collect metrics to return\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \"\"\"\n\u001b[1;32m    520\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[0;32m--> 521\u001b[0;31m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_compute_gradients\u001b[0;34m(self, loss, var_list, grad_loss, tape)\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0mvar_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/gradients\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m       \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     self._assert_valid_dtypes([\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_get_gradients\u001b[0;34m(self, tape, loss, var_list, grad_loss)\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_get_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;34m\"\"\"Called in `minimize` to compute gradients from loss.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m     \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[0m\n\u001b[1;32m   1088\u001b[0m         \u001b[0moutput_gradients\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0msources_raw\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_sources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m         unconnected_gradients=unconnected_gradients)\n\u001b[0m\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_persistent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/imperative_grad.py\u001b[0m in \u001b[0;36mimperative_grad\u001b[0;34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[0m\n\u001b[1;32m     75\u001b[0m       \u001b[0moutput_gradients\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m       \u001b[0msources_raw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m       compat.as_str(unconnected_gradients.value))\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/eager/backprop.py\u001b[0m in \u001b[0;36m_gradient_function\u001b[0;34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[0m\n\u001b[1;32m    157\u001b[0m       \u001b[0mgradient_name_scope\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mforward_pass_name_scope\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient_name_scope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgrad_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmock_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mout_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py\u001b[0m in \u001b[0;36m_SumGrad\u001b[0;34m(op, grad)\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m           \u001b[0mnew_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mgrad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;31m# If shape is not fully defined (but rank is), we use Shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_0_shape\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \"\"\"\n\u001b[0;32m--> 196\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8389\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8390\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0;32m-> 8391\u001b[0;31m         _ctx, \"Reshape\", name, tensor, shape)\n\u001b[0m\u001b[1;32m   8392\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8393\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train.reshape(-1,1,9), y_train,\n",
    "          validation_data=(X_val.reshape(-1,1,9), y_val), epochs = 100, batch_size=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d74690ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 123.61 RMSE\n",
      "Test Score: 248.64 RMSE\n"
     ]
    }
   ],
   "source": [
    "trainPredict = model.predict(X_train.reshape(-1,1,9))\n",
    "testPredict = model.predict(X_test.reshape(-1,1,9))\n",
    "valPredict = model.predict(X_val.reshape(-1,1,9))\n",
    "# invert predictions\n",
    "trainPredict = ss_y.inverse_transform(trainPredict)\n",
    "trainY = ss_y.inverse_transform([y_train])\n",
    "testPredict = ss_y.inverse_transform(testPredict)\n",
    "testY = ss_y.inverse_transform([y_test])\n",
    "valPredict = ss_y.inverse_transform(valPredict)\n",
    "valY = ss_y.inverse_transform([y_val])\n",
    "# calculate root mean squared error\n",
    "trainScore = np.sqrt(mean_squared_error(trainY[0], trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = np.sqrt(mean_squared_error(testY[0], testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8f043904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[146.13475],\n",
       "       [146.13475],\n",
       "       [146.13475],\n",
       "       ...,\n",
       "       [146.13475],\n",
       "       [146.13475],\n",
       "       [146.13475]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "61776042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#trainPredictPlot = [np.nan for x in range(31682)]  # N = size of list you want\n",
    "#trainPredictPlot[4:len(trainPredict)+4] = trainPredict\n",
    "\n",
    "# shift test predictions for plotting\n",
    "#testPredictPlot = [np.nan for x in range(31682)] \n",
    "#testPredictPlot[27916:len(df)] = testPredict\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot((df['texts'][27916:len(df)].astype(float).to_numpy()))\n",
    "#plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredict)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
